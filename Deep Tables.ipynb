{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "policy=list(set(train['Policy_Sales_Channel']).intersection(set(test['Policy_Sales_Channel'])))\n",
    "train['Policy_Sales_Channel']=train['Policy_Sales_Channel'].apply(lambda x: x if x in policy else 'Missing')\n",
    "test['Policy_Sales_Channel']=test['Policy_Sales_Channel'].apply(lambda x: x if x in policy else 'Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1    Male   44                1         28.0                   0   \n",
       "1   2    Male   76                1          3.0                   0   \n",
       "2   3    Male   47                1         28.0                   0   \n",
       "3   4    Male   21                1         11.0                   1   \n",
       "4   5  Female   29                1         41.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                   26      217   \n",
       "1    1-2 Year             No         33536.0                   26      183   \n",
       "2   > 2 Years            Yes         38294.0                   26       27   \n",
       "3    < 1 Year             No         28619.0                  152      203   \n",
       "4    < 1 Year             No         27496.0                  152       39   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test])\n",
    "data.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "cat_col=['Gender', 'Driving_License', 'Region_Code','Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage','Policy_Sales_Channel']\n",
    "for col in cat_col:\n",
    "    data[col]=data[col].astype(str)\n",
    "    data[col]=le.fit_transform(data[col])\n",
    "    \n",
    "train2=data[~data['Response'].isna()]\n",
    "test2=data[data['Response'].isna()]\n",
    "\n",
    "X=train2.drop(['Response','Policy_Sales_Channel'],axis=1)\n",
    "y=train2['Response']\n",
    "X_test=test2[X.columns]\n",
    "cat_col=['Gender', 'Driving_License', 'Region_Code','Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptables.models.deeptable import DeepTable, ModelConfig\n",
    "from deeptables.datasets import dsutils\n",
    "from deeptables.models import deeptable\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler , EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():  \n",
    "    conf = ModelConfig( dnn_params={'hidden_units':((128, 0.2, True),(128, 0.2, True),),\n",
    "                                   'dnn_activation':'relu',},\n",
    "                        fixed_embedding_dim=True,\n",
    "                        embeddings_output_dim=10,\n",
    "                        nets =['pnn_nets'],\n",
    "                        stacking_op = 'add',\n",
    "                        metrics=['accuracy'],\n",
    "                        apply_class_weight=False,\n",
    "                        categorical_columns = cat_col\n",
    "                        )\n",
    "    dt = DeepTable(config = conf)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 \n",
    "batch_size = 2000\n",
    "seeds = [32,432 ,73]\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience = 5 ,restore_best_weights= True)\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) #for plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      " rows of train = 304887 rows of holdout = 76222\n",
      "2 class detected, {0.0, 1.0}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.023377180099487305\n",
      "Imputation cost:0.11058306694030762\n",
      "Categorical encoding cost:0.1085209846496582\n",
      "fit_transform cost:0.2991211414337158\n",
      "transform_X cost:2.570528030395508\n",
      "transform_y cost:0.0017039775848388672\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (6)', 'input_continuous_all: (3)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [4, 4, 55, 4, 5, 4]\n",
      "output_dims: [10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 63)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-outer_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-dnn: input_shape (None, 93), output_shape (None, 128)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Model has been saved to:dt_output/dt_20200913 083846_pnn_nets/pnn_nets.h5\n",
      "transform_X cost:2.8317348957061768\n",
      "transform_y cost:0.0020749568939208984\n",
      "transform_X cost:4.499037981033325\n",
      "predict_proba cost:5.627284049987793\n",
      "LGB Val CV= 87.74107098579407\n",
      "__________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Fold 1\n",
      " rows of train = 304887 rows of holdout = 76222\n",
      "2 class detected, {0.0, 1.0}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.018664121627807617\n",
      "Imputation cost:0.09655404090881348\n",
      "Categorical encoding cost:0.10945725440979004\n",
      "fit_transform cost:0.2824819087982178\n",
      "transform_X cost:2.6637187004089355\n",
      "transform_y cost:0.0014340877532958984\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (6)', 'input_continuous_all: (3)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [4, 4, 55, 4, 5, 4]\n",
      "output_dims: [10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 63)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-outer_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-dnn: input_shape (None, 93), output_shape (None, 128)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Model has been saved to:dt_output/dt_20200913 084221_pnn_nets/pnn_nets.h5\n",
      "transform_X cost:2.645611047744751\n",
      "transform_y cost:0.0014128684997558594\n",
      "transform_X cost:4.278663873672485\n",
      "predict_proba cost:5.210844278335571\n",
      "LGB Val CV= 87.74501085281372\n",
      "__________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Fold 2\n",
      " rows of train = 304887 rows of holdout = 76222\n",
      "2 class detected, {0.0, 1.0}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.019262075424194336\n",
      "Imputation cost:0.0928809642791748\n",
      "Categorical encoding cost:0.09935593605041504\n",
      "fit_transform cost:0.26671314239501953\n",
      "transform_X cost:2.566718339920044\n",
      "transform_y cost:0.001421213150024414\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (6)', 'input_continuous_all: (3)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [4, 4, 55, 4, 5, 4]\n",
      "output_dims: [10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 63)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-outer_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-dnn: input_shape (None, 93), output_shape (None, 128)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Model has been saved to:dt_output/dt_20200913 084508_pnn_nets/pnn_nets.h5\n",
      "transform_X cost:2.7330682277679443\n",
      "transform_y cost:0.0014829635620117188\n",
      "transform_X cost:4.336580276489258\n",
      "predict_proba cost:5.281051874160767\n",
      "LGB Val CV= 87.73451447486877\n",
      "__________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Fold 3\n",
      " rows of train = 304887 rows of holdout = 76222\n",
      "2 class detected, {0.0, 1.0}, so inferred as a [binary classification] task\n",
      "Preparing features cost:0.018810033798217773\n",
      "Imputation cost:0.09473395347595215\n",
      "Categorical encoding cost:0.1036977767944336\n",
      "fit_transform cost:0.27356529235839844\n",
      "transform_X cost:2.6802098751068115\n",
      "transform_y cost:0.0016350746154785156\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (6)', 'input_continuous_all: (3)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [4, 4, 55, 4, 5, 4]\n",
      "output_dims: [10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 63)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-outer_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-dnn: input_shape (None, 93), output_shape (None, 128)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Model has been saved to:dt_output/dt_20200913 084725_pnn_nets/pnn_nets.h5\n",
      "transform_X cost:2.6158969402313232\n",
      "transform_y cost:0.0014629364013671875\n",
      "transform_X cost:4.222971200942993\n",
      "predict_proba cost:5.146953105926514\n",
      "LGB Val CV= 87.74107098579407\n",
      "__________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Fold 4\n",
      " rows of train = 304887 rows of holdout = 76222\n",
      "2 class detected, {0.0, 1.0}, so inferred as a [binary classification] task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features cost:0.018023014068603516\n",
      "Imputation cost:0.0950620174407959\n",
      "Categorical encoding cost:0.10158205032348633\n",
      "fit_transform cost:0.2695589065551758\n",
      "transform_X cost:2.6078779697418213\n",
      "transform_y cost:0.0015380382537841797\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (6)', 'input_continuous_all: (3)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [4, 4, 55, 4, 5, 4]\n",
      "output_dims: [10, 10, 10, 10, 10, 10]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 63)\n",
      "---------------------------------------------------------\n",
      "nets: ['pnn_nets']\n",
      "---------------------------------------------------------\n",
      "pnn-inner_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-outer_product: input_shape list(6), output_shape (None, 15)\n",
      "pnn-dnn: input_shape (None, 93), output_shape (None, 128)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "Model has been saved to:dt_output/dt_20200913 084950_pnn_nets/pnn_nets.h5\n",
      "transform_X cost:3.131855010986328\n",
      "transform_y cost:0.002007007598876953\n",
      "transform_X cost:4.721670866012573\n",
      "predict_proba cost:5.7337729930877686\n",
      "LGB Val CV= 87.74107098579407\n",
      "__________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "X_train_cv,y_train_cv = X.copy(), y.copy()\n",
    "pred=np.zeros((len(test2),1))\n",
    "sssf = StratifiedShuffleSplit(n_splits=5, test_size = 0.2,random_state=1)\n",
    "for i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):  \n",
    "    \n",
    "    steps_per_epoch = len(X_train_cv.iloc[idxT])//batch_size  \n",
    "    validation_steps = len(X_train_cv.iloc[idxV])//batch_size\n",
    "    \n",
    "    print('Fold',i)\n",
    "    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n",
    "    \n",
    "    dt_cv =  build_model()\n",
    "    model_dnn_cv, history_cv = dt_cv.fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n",
    "                                                 validation_data = (X_train_cv.iloc[idxV],y_train_cv.iloc[idxV]),\n",
    "                                                 steps_per_epoch = steps_per_epoch,\n",
    "                                                 validation_steps = validation_steps,\n",
    "                                                 batch_size=batch_size, epochs=epochs, \n",
    "                                                 verbose=0, callbacks=[early_stop,annealer])\n",
    "    \n",
    "    val_stats = dt_cv.evaluate(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV], batch_size=batch_size, verbose=0)\n",
    "    pred+=dt_cv.predict_proba(X_test)\n",
    "    \n",
    "    acc= val_stats['accuracy']*100\n",
    "    scores.append(acc)      \n",
    "\n",
    "    print ('LGB Val CV=',acc)\n",
    "    print('_'*130)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381110</th>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381111</th>\n",
       "      <td>0.072189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381112</th>\n",
       "      <td>0.066493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381113</th>\n",
       "      <td>0.001948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381114</th>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Response\n",
       "id              \n",
       "381110  0.000155\n",
       "381111  0.072189\n",
       "381112  0.066493\n",
       "381113  0.001948\n",
       "381114  0.000113"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=pred/5\n",
    "sub=pd.DataFrame()\n",
    "sub['Response']=pred.ravel()\n",
    "sub.index=test.id\n",
    "sub=sub[['Response']]\n",
    "sub.to_csv('DeepTable.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
